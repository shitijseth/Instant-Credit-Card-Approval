{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "import pandas as pd\n",
    "from openpyxl.reader.excel import load_workbook\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from time import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn import neighbors, datasets\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "import random\n",
    "from statistics import mean, stdev\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics    \n",
    "from sklearn.svm import SVC\n",
    "from heapq import nlargest\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Opening the Excel file with data\n",
    "filepath=\"credit_card_data.xlsx\" #Enter full filepath here\n",
    "wb=load_workbook(filepath)\n",
    "sheet=wb.active\n",
    "\n",
    "#set-wise data read-in \n",
    "def read(num):\n",
    "    x, y = [], []\n",
    "    \n",
    "# 1. Male, 2. Age, 3. Debt, 4. Married, 5. Bank Customer, 6. Education Level, 7. Ethnicity, 8. Years Employed, \n",
    "# 9.Prior Default, 10. Employed, 11. Credit Score, 12. Driver's License, 13. Citizen, 14. Zip Code, 15. Income\n",
    "\n",
    "#Considering data for only 4 columns\n",
    "    cols = [8, 9, 10, 11]\n",
    "    for i in cols:\n",
    "        x.append(sheet.cell(row=num+1,column=i).value)\n",
    "    y.append(sheet.cell(row=num+1,column=16).value)\n",
    "    return x, y\n",
    "\n",
    "x_data, y_data = [], []\n",
    "for j in range(1, 690):\n",
    "    valx, valy = read(j)\n",
    "    \n",
    "#Checks for missing data    \n",
    "    \n",
    "    if \"?\" in valx:\n",
    "        print(j, read(j))\n",
    "    x_data.append(valx)    \n",
    "    y_data.append(valy)\n",
    "print(x_data, y_data)\n",
    "print(len(x_data[0]), len(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Shuffle the order of the data\n",
    "toshuffle = list(zip(x_data, y_data))\n",
    "x_data, y_data = zip(*toshuffle)\n",
    "\n",
    "#Splitting into train and test set\n",
    "cut = 600\n",
    "train_x, train_y = x_data[0:cut], y_data[0:cut]\n",
    "test_x, test_y = x_data[cut:690], y_data[cut:690]\n",
    "\n",
    "train_x, train_y = np.asarray(train_x), np.asarray(train_y)\n",
    "test_x, test_y = np.asarray(test_x), np.asarray(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network (Shitij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Runs 10 iterations of ANN and gives out the mean accuracy of the highest 5 accuracies\n",
    "per_acc = []\n",
    "for i in range(10):\n",
    "   \n",
    "#Calling MLP classifier\n",
    "    ann = MLPClassifier(activation= 'tanh', hidden_layer_sizes= (100,), learning_rate= 'constant',  max_iter= 100, \n",
    "                      solver= 'lbfgs', tol= 0.01, validation_fraction= 0.1, early_stopping=True,\n",
    "                      n_iter_no_change=100, verbose=True)\n",
    "    \n",
    "#Training the network\n",
    "    train_y = np.asarray(train_y)\n",
    "    ann.fit(train_x, train_y.ravel())\n",
    "\n",
    "#Gives probabilistic predictions\n",
    "    prediction = ann.predict_proba(test_x)\n",
    "\n",
    "    c = 0\n",
    "    for each in range(len(prediction)):\n",
    "        if np.argmax(prediction[each]) == test_y[each]:\n",
    "            c += 1\n",
    "\n",
    "    per =  float(c / len(prediction)) * 100\n",
    "    print(per)\n",
    "    per_acc.append(per)\n",
    "\n",
    "print('Mean:', mean(per_acc))\n",
    "sort = nlargest(5, per_acc)\n",
    "print('New Mean:', mean(sort))\n",
    "x = np.arange(0, 10)\n",
    "plt.plot(x, per_acc)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Percentage Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Yusri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs 10 iterations of LR and gives out the mean accuracy of the highest 5 accuracies\n",
    "per_acc=[]                                                                   \n",
    "for i in range(10):\n",
    "\n",
    "    lr = LogisticRegression(C=0.9, penalty='l1', tol=0.01)\n",
    "    lr.fit(train_x, train_y)\n",
    "    y_pred=lr.predict(test_x)\n",
    "\n",
    "    score = metrics.accuracy_score(test_y, y_pred)\n",
    "    print(score)\n",
    "    per_acc.append(score)\n",
    "    \n",
    "print(mean(per_acc))\n",
    "sort = nlargest(5, per_acc)\n",
    "print('New Mean:', mean(sort))\n",
    "x = list(range(len(per_acc)))\n",
    "plt.plot(x,per_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (YuanJea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Just one iteration as it returns consistent results for every iteration \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15, weights='uniform', algorithm='auto', leaf_size=1, p=1 ,metric='minkowski')\n",
    "\n",
    "knn.fit(train_x, train_y)\n",
    "\n",
    "predicted = knn.predict_proba(test_x)\n",
    "\n",
    "c = 0\n",
    "for each in range(len(predicted)):\n",
    "    if np.argmax(predicted[each]) == test_y[each]:    \n",
    "        c += 1\n",
    "\n",
    "print(\"Percentage Accuracy: \", float(c/len(predicted))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (Yusri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist=[]\n",
    "for i in range(10):\n",
    "    \n",
    "    svm = SVC(kernel= 'linear', C= 1.) #svm Classifier\n",
    "    svm.fit(train_x, train_y)          #Train the model using the training sets\n",
    "    y_pred = svm.predict(test_x)               #Predict the response for test datasetfrom sklearn import metric\n",
    "\n",
    "    x = metrics.accuracy_score(test_y, y_pred)*100\n",
    "\n",
    "    print(\"Accuracy:\" , x )\n",
    "    mylist.append(x)\n",
    "\n",
    "print(\"Mean: \" , mean(mylist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (Deryck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Runs 10 iterations of RF and gives out the mean accuracy of the highest 5 accuracies\n",
    "\n",
    "per_acc=[]                                                                   \n",
    "for i in range(10):\n",
    "    rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',max_depth=None, max_features='auto',\n",
    "                                max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=2,\n",
    "                                min_samples_split=4, min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                                oob_score=False, verbose=0, warm_start=False)\n",
    "    rf.fit(train_x, train_y)\n",
    "    y_pred = rf.predict(test_x)\n",
    "    print(\"Random Forest classifier has accuracy of: \", rf.score(test_x, test_y))\n",
    "    per_acc.append(rf.score(test_x, test_y))\n",
    "    \n",
    "print(mean(per_acc))\n",
    "sort = nlargest(5, per_acc)\n",
    "print('New Mean:', mean(sort))\n",
    "\n",
    "x = list(range(len(per_acc)))\n",
    "plt.plot(x,per_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees (Deryck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_acc=[]\n",
    "for i in range(10):\n",
    "    tree = DecisionTreeClassifier(max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                  min_samples_leaf=3, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False,\n",
    "                                  random_state=None, splitter='best')\n",
    "    tree = tree.fit(train_x, train_y)\n",
    "    print(\"Accuracy:\", tree.score(test_x, test_y))\n",
    "    per_acc.append(tree.score(test_x, test_y))\n",
    "    \n",
    "\n",
    "print(mean(per_acc))\n",
    "sort = nlargest(5, per_acc)\n",
    "print('New Mean:', mean(sort))\n",
    "\n",
    "x = list(range(len(per_acc)))\n",
    "plt.plot(x,per_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembling by using a voting classifier\n",
    "\n",
    "alg = [('ann', ann), ('lr', lr), ('knn', knn), ('svm', svm), ('rf', rf), ('dt', tree)]\n",
    "\n",
    "#Creates all possible combinations of the individual algorithms used\n",
    "combs, allcombs = [], []\n",
    "for i in range(1, len(alg)+1):\n",
    "    els = [list(x) for x in combinations(alg, i)]\n",
    "    combs.append(els)\n",
    "\n",
    "for i in combs:\n",
    "    for j in i:\n",
    "        allcombs.append(j)\n",
    "        print(j)\n",
    "\n",
    "# allcombs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling for all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Returns mean, standard deviation and run time for accuracies from 50 iterations of each combination.\n",
    "#Also returns the mean and standard deviation for the top 5 iterations in terms of the accuracies\n",
    "\n",
    "mod4, accs4, times4, allofem4 = [], [], [], []\n",
    "counter = 0\n",
    "for i in allcombs:\n",
    "    acc = []\n",
    "    start = time()\n",
    "    for j in range(0, 50):\n",
    "#Voting classifier from scikit-learn\n",
    "        eclf1 = VotingClassifier(estimators=[i[0]], voting='soft')\n",
    "        eclf1 = eclf1.fit(train_x, train_y.ravel())\n",
    "        pred = eclf1.predict(test_x)\n",
    "        acc.append(metrics.accuracy_score(test_y, pred))\n",
    "    end = time()\n",
    "    tt = end - start\n",
    "#Selects 5 largest accuracies\n",
    "    sort = nlargest(5, acc)\n",
    "    print(i)\n",
    "    print('Mean:', mean(acc))\n",
    "    print('Stdev:', stdev(acc))\n",
    "    print('New Mean:', mean(sort))\n",
    "    print('New Stdev:', stdev(sort))\n",
    "    print('Avg Time:', tt/50)\n",
    "    mod4.append(i)\n",
    "    accs4.append((mean(acc), stdev(acc), mean(sort), stdev(sort)))\n",
    "    times4.append(tt/50)\n",
    "    allofem4.append((i, mean(acc), stdev(acc), mean(sort), stdev(sort), tt/50))\n",
    "    counter += 1\n",
    "    print('%d iterations done out of 63' %counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints cumulative results from the above cell\n",
    "allofem4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
