{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "import pandas as pd\n",
    "from openpyxl.reader.excel import load_workbook\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from time import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn import neighbors, datasets\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "import random\n",
    "from statistics import mean, stdev\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics    \n",
    "from sklearn.svm import SVC\n",
    "from heapq import nlargest\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.25, 1, 1, 1], [3.04, 1, 1, 6], [1.5, 1, 0, 0], [3.75, 1, 1, 5], [1.71, 1, 0, 0], [2.5, 1, 0, 0], [6.5, 1, 0, 0], [0.04, 1, 0, 0], [3.96, 1, 0, 0], [3.165, 1, 0, 0], [2.165, 0, 0, 0], [4.335, 1, 0, 0], [1, 1, 0, 0], [0.04, 0, 0, 0], [5, 1, 1, 7], [0.25, 1, 1, 10], [0.96, 1, 1, 3], [3.17, 1, 1, 10], [0.665, 1, 0, 0], [0.75, 1, 1, 7], [2.5, 1, 1, 17], [0.835, 1, 0, 0], [7.875, 1, 1, 6], [3.085, 1, 1, 1], [0.5, 1, 1, 3], [1.5, 1, 1, 2], [5.165, 1, 1, 9], [15, 1, 1, 17], [7, 1, 1, 3], [5, 1, 1, 6], [5.04, 1, 1, 5], [7.96, 1, 1, 8], [7.585, 1, 1, 15], [5, 1, 0, 0], [0.415, 1, 1, 5], [2, 1, 1, 11], [1.835, 1, 1, 12], [0.5, 1, 1, 2], [0.25, 1, 1, 2], [14.415, 1, 1, 11], [4.5, 1, 1, 12], [5.335, 1, 1, 11], [0.75, 1, 1, 1], [8.625, 1, 1, 6], [28.5, 1, 1, 40], [2.625, 1, 1, 11], [0.125, 1, 1, 23], [6.04, 1, 1, 3], [3.5, 0, 0, 0], [0.165, 0, 0, 0], [0.875, 1, 0, 0], [1.75, 1, 0, 0], [0.04, 1, 0, 0], [0, 1, 0, 0], [7.415, 1, 0, 0], [0.835, 1, 0, 0], [0.085, 1, 0, 0], [5, 1, 0, 0], [5.75, 0, 0, 0], [6, 1, 1, 11], [1.25, 1, 1, 4], [3, 1, 1, 9], [1.5, 1, 1, 2], [1.585, 1, 1, 1], [4.29, 1, 1, 1], [1.54, 1, 1, 1], [2, 1, 1, 11], [0.25, 1, 1, 3], [1.46, 1, 1, 7], [1.625, 1, 1, 1], [1.585, 1, 0, 0], [13.5, 1, 0, 0], [10.75, 1, 0, 0], [1.625, 0, 0, 0], [0.375, 1, 1, 1], [0.125, 1, 0, 0], [0.585, 1, 0, 0], [2.5, 1, 1, 1], [0.25, 1, 0, 0], [0, 1, 1, 1], [2, 1, 0, 0], [0.25, 1, 0, 0], [0.455, 1, 0, 0], [5, 1, 0, 0], [4, 1, 0, 0], [1, 1, 0, 0], [0, 1, 0, 0], [5, 1, 0, 0], [0.5, 1, 0, 0], [9.46, 1, 0, 0], [1.5, 1, 0, 0], [0.5, 1, 0, 0], [0.125, 1, 0, 0], [3, 1, 0, 0], [1, 1, 1, 2], [0.25, 1, 0, 0], [4, 1, 0, 0], [0.375, 1, 1, 2], [2.25, 1, 1, 2], [5.75, 1, 1, 2], [0, 1, 1, 20], [0.5, 1, 0, 0], [4.5, 1, 0, 0], [10, 1, 0, 0], [0.795, 1, 1, 5], [3.5, 1, 1, 3], [0.5, 1, 1, 3], [0.875, 1, 0, 0], [1, 1, 1, 3], [1.375, 1, 1, 3], [1.29, 1, 1, 2], [11.5, 1, 1, 7], [6.29, 1, 1, 15], [14, 1, 1, 6], [0.335, 1, 1, 1], [0.04, 1, 1, 1], [1.21, 1, 1, 67], [1.5, 1, 1, 12], [7.375, 1, 1, 3], [8.5, 1, 1, 5], [7.5, 1, 1, 6], [2.5, 1, 1, 12], [2.5, 1, 1, 7], [3.25, 1, 1, 2], [0.835, 1, 0, 0], [13, 1, 1, 1], [2.25, 1, 1, 1], [6.5, 1, 1, 6], [2.5, 1, 1, 6], [5.5, 1, 1, 12], [6, 1, 0, 0], [0.5, 1, 1, 3], [4.25, 1, 1, 6], [1.625, 1, 1, 6], [5, 1, 1, 2], [0.625, 1, 1, 9], [0, 1, 1, 15], [1.75, 1, 1, 8], [2, 1, 1, 1], [5.085, 1, 1, 9], [2.75, 1, 1, 6], [2.375, 1, 1, 3], [8, 1, 1, 14], [4, 1, 1, 7], [5.5, 1, 1, 14], [0.415, 1, 1, 11], [4, 1, 1, 14], [4.25, 1, 1, 12], [1.085, 1, 1, 11], [5.5, 1, 1, 3], [0, 1, 1, 11], [2.54, 1, 1, 1], [0, 1, 1, 14], [4.165, 1, 1, 2], [0.04, 1, 1, 1], [1, 1, 1, 4], [1.75, 1, 1, 2], [1.665, 1, 1, 1], [0.04, 1, 0, 0], [11, 1, 0, 0], [1.75, 1, 0, 0], [1, 1, 0, 0], [0.04, 1, 0, 0], [9, 1, 0, 0], [1.5, 0, 0, 0], [0.25, 1, 0, 0], [15, 1, 0, 0], [8, 1, 0, 0], [8.5, 1, 0, 0], [1.335, 1, 0, 0], [0.375, 1, 0, 0], [3, 1, 0, 0], [1.415, 1, 0, 0], [1.21, 1, 1, 4], [1.96, 1, 1, 14], [15, 1, 1, 20], [0.5, 1, 1, 4], [0.165, 1, 1, 3], [5.5, 1, 1, 7], [2.585, 1, 1, 7], [12.5, 1, 1, 9], [3.5, 1, 1, 1], [5, 1, 1, 7], [2.5, 1, 1, 5], [1.625, 1, 1, 2], [3, 1, 0, 0], [5.125, 1, 0, 0], [2.5, 1, 0, 0], [3.085, 1, 1, 6], [8.5, 1, 1, 7], [1.5, 1, 1, 8], [3.165, 1, 1, 3], [15.5, 1, 1, 12], [2, 1, 1, 3], [0.04, 1, 1, 9], [1.25, 1, 1, 1], [2.25, 1, 0, 0], [0.71, 1, 1, 2], [0.085, 1, 1, 1], [14, 1, 1, 8], [5.665, 1, 1, 6], [4.5, 1, 1, 7], [6.5, 1, 1, 16], [10, 1, 1, 14], [5.5, 1, 0, 0], [18, 1, 1, 15], [3.5, 1, 1, 9], [5.25, 1, 1, 1], [3.5, 1, 0, 0], [7, 1, 1, 8], [5, 1, 1, 5], [8.665, 1, 1, 5], [1, 1, 1, 4], [2.29, 1, 1, 3], [20, 1, 1, 7], [1.375, 1, 0, 0], [0.085, 1, 0, 0], [0.125, 1, 0, 0], [0.25, 1, 0, 0], [0.5, 1, 0, 0], [2.46, 0, 0, 0], [2, 1, 1, 2], [0.665, 1, 0, 0], [0.625, 1, 1, 7], [13.875, 1, 1, 2], [4.5, 1, 1, 4], [5.75, 1, 0, 0], [10, 1, 1, 13], [2.085, 1, 1, 5], [0, 1, 0, 0], [1.415, 1, 1, 1], [4.58, 1, 0, 0], [2.5, 1, 1, 6], [2.5, 1, 0, 0], [1.75, 1, 1, 3], [11, 1, 0, 0], [1.5, 1, 1, 2], [2.04, 1, 1, 1], [14, 1, 1, 1], [0.29, 1, 1, 11], [0.29, 1, 1, 6], [20, 1, 1, 11], [5, 1, 1, 6], [1, 1, 1, 11], [0.46, 1, 1, 1], [1.085, 0, 0, 0], [2, 0, 0, 0], [0.5, 0, 0, 0], [0.04, 0, 0, 0], [0.165, 0, 0, 0], [5.75, 0, 0, 0], [0, 0, 0, 0], [0.335, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0.04, 0, 0, 0], [0, 0, 0, 0], [1.25, 0, 0, 0], [0.125, 1, 0, 0], [0.21, 0, 0, 0], [1.25, 0, 0, 0], [0.04, 0, 0, 0], [0.125, 0, 0, 0], [2.25, 0, 0, 0], [0.54, 0, 0, 0], [0.29, 0, 0, 0], [0.165, 0, 0, 0], [0.085, 1, 0, 0], [0.25, 0, 0, 0], [0.125, 0, 0, 0], [0.25, 0, 0, 0], [0.25, 0, 1, 1], [0.125, 0, 1, 2], [0.165, 0, 1, 1], [0.29, 0, 1, 1], [0.165, 0, 1, 1], [0, 0, 0, 0], [0.5, 0, 0, 0], [1, 0, 1, 1], [0.165, 0, 1, 1], [0.125, 0, 1, 2], [0, 0, 1, 1], [3.04, 0, 1, 2], [4, 0, 1, 1], [1.75, 0, 1, 2], [0.665, 0, 1, 1], [3.335, 0, 1, 2], [6.5, 0, 1, 1], [0.25, 0, 0, 0], [0.5, 0, 0, 0], [0.085, 0, 0, 0], [1.5, 0, 0, 0], [0, 1, 0, 0], [4.5, 0, 0, 0], [0.415, 0, 0, 0], [0.25, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0], [2.335, 0, 0, 0], [0.125, 0, 0, 0], [0.415, 0, 0, 0], [0.25, 0, 0, 0], [0.5, 1, 0, 0], [0.25, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1.5, 0, 0, 0], [1.5, 0, 0, 0], [10, 0, 0, 0], [0.375, 0, 0, 0], [0.25, 1, 1, 11], [1.165, 0, 0, 0], [1, 0, 0, 0], [0.04, 0, 0, 0], [3, 0, 0, 0], [2.5, 0, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0.5, 0, 0, 0], [0.165, 0, 0, 0], [1, 0, 0, 0], [0.5, 0, 0, 0], [2, 0, 0, 0], [0.75, 0, 0, 0], [3, 0, 0, 0], [0.04, 0, 0, 0], [0.5, 0, 0, 0], [0, 0, 0, 0], [0.5, 0, 0, 0], [0, 0, 0, 0], [2.5, 0, 0, 0], [0.585, 1, 1, 3], [2.25, 0, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0], [1.5, 0, 0, 0], [0.585, 0, 0, 0], [0.25, 0, 0, 0], [1, 0, 1, 2], [0.165, 0, 0, 0], [0.04, 0, 0, 0], [0.165, 0, 0, 0], [0, 0, 0, 0], [5.5, 0, 0, 0], [0.085, 0, 0, 0], [0, 0, 0, 0], [0.29, 0, 0, 0], [0.165, 0, 1, 2], [13.875, 0, 1, 1], [0.165, 0, 0, 0], [0.165, 0, 0, 0], [3, 0, 0, 0], [0.75, 0, 0, 0], [7, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0], [0.125, 0, 0, 0], [1, 0, 0, 0], [0.125, 0, 0, 0], [2, 0, 0, 0], [0.125, 0, 0, 0], [4, 0, 0, 0], [2.25, 0, 0, 0], [0.165, 0, 0, 0], [4.5, 0, 0, 0], [5, 0, 0, 0], [1.585, 0, 0, 0], [1.5, 0, 0, 0], [0.54, 0, 0, 0], [0.5, 0, 0, 0], [0, 0, 0, 0], [0.085, 0, 0, 0], [1, 0, 0, 0], [0.21, 0, 0, 0], [0.25, 0, 0, 0], [1, 0, 0, 0], [0.25, 0, 0, 0], [0.54, 0, 0, 0], [0.04, 0, 0, 0], [0.125, 0, 0, 0], [1.25, 0, 0, 0], [0.085, 0, 0, 0], [0.29, 0, 0, 0], [0.29, 0, 0, 0], [3.085, 0, 0, 0], [0.75, 0, 0, 0], [1.085, 0, 0, 0], [0, 0, 0, 0], [1, 0, 1, 1], [0.085, 0, 1, 1], [0.335, 0, 1, 4], [0, 0, 1, 5], [1.25, 0, 1, 1], [0.085, 0, 0, 0], [0, 0, 0, 0], [0.125, 0, 0, 0], [3.25, 0, 0, 0], [0.125, 0, 0, 0], [0.54, 0, 0, 0], [0.375, 0, 1, 2], [0, 0, 0, 0], [1, 0, 0, 0], [1.5, 0, 0, 0], [1.75, 0, 0, 0], [1.165, 0, 0, 0], [1.5, 0, 0, 0], [0.25, 0, 0, 0], [0.25, 0, 0, 0], [0.04, 0, 0, 0], [0.29, 0, 0, 0], [0.085, 0, 0, 0], [1.5, 0, 0, 0], [0.165, 0, 0, 0], [0.085, 0, 0, 0], [0.5, 0, 0, 0], [2.415, 0, 0, 0], [0, 0, 1, 4], [0, 0, 1, 3], [0, 0, 0, 0], [0, 0, 1, 1], [0.375, 0, 1, 2], [1, 0, 1, 11], [0, 0, 1, 2], [0.125, 0, 0, 0], [0.04, 0, 0, 0], [0, 0, 0, 0], [0.165, 0, 0, 0], [0, 0, 0, 0], [0, 0, 1, 1], [0.5, 0, 0, 0], [1.5, 0, 0, 0], [3.5, 0, 0, 0], [3.75, 0, 0, 0], [0.085, 0, 0, 0], [0.04, 0, 0, 0], [5, 0, 0, 0], [1.5, 0, 0, 0], [0, 0, 0, 0], [0.085, 0, 1, 4], [0.125, 0, 0, 0], [0, 0, 1, 10], [0, 0, 1, 1], [2.79, 0, 1, 1], [2.5, 0, 1, 2], [0.04, 0, 1, 3], [0.75, 0, 0, 0], [0.415, 0, 0, 0], [0.085, 0, 0, 0], [0.04, 0, 0, 0], [0.125, 0, 0, 0], [1, 0, 0, 0], [0.125, 0, 0, 0], [0.75, 0, 0, 0], [0.085, 0, 0, 0], [10, 0, 0, 0], [0.415, 0, 0, 0], [0.165, 0, 1, 6], [0.415, 0, 1, 1], [1.75, 0, 1, 10], [0.04, 0, 1, 2], [1.165, 0, 0, 0], [0.04, 0, 1, 2], [0.085, 0, 0, 0], [0.04, 0, 0, 0], [0, 0, 0, 0], [2.75, 1, 1, 1], [4.625, 1, 1, 2], [6.5, 1, 1, 14], [6, 1, 0, 0], [3, 1, 0, 0], [1.5, 1, 0, 0], [1.04, 1, 0, 0], [1.665, 1, 1, 3], [1.46, 1, 1, 5], [1.625, 1, 1, 3], [3.5, 1, 1, 10], [0, 1, 1, 1], [4.75, 1, 1, 2], [1.085, 1, 1, 1], [7, 1, 1, 16], [0.75, 1, 1, 2], [1.835, 1, 1, 19], [2, 1, 1, 1], [2.25, 1, 1, 1], [1.75, 1, 1, 2], [0, 1, 0, 0], [2.5, 1, 0, 0], [0, 1, 0, 0], [2.585, 1, 0, 0], [4, 1, 1, 4], [1.75, 1, 1, 5], [0.585, 1, 1, 4], [0.125, 1, 1, 5], [2.25, 1, 1, 5], [1.29, 1, 1, 1], [1.75, 1, 1, 10], [2.415, 1, 0, 0], [2.5, 1, 0, 0], [0.21, 1, 0, 0], [1, 1, 0, 0], [6.75, 1, 1, 3], [0.21, 1, 1, 1], [2.75, 1, 0, 0], [1.75, 1, 0, 0], [0.75, 1, 0, 0], [0, 1, 0, 0], [7.5, 1, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0], [3.75, 1, 0, 0], [0.25, 1, 0, 0], [2, 1, 0, 0], [1, 1, 0, 0], [0.835, 1, 0, 0], [1.165, 1, 0, 0], [0.5, 1, 1, 10], [1.5, 1, 0, 0], [2.625, 1, 1, 6], [1.875, 1, 1, 6], [0.75, 1, 1, 7], [16, 1, 0, 0], [12.75, 1, 1, 1], [0, 1, 1, 11], [5.375, 1, 1, 9], [4, 1, 1, 14], [0.75, 1, 1, 4], [0.21, 1, 1, 6], [7.5, 1, 1, 2], [1.085, 1, 1, 16], [0.04, 1, 0, 0], [2.29, 1, 1, 7], [3.5, 1, 1, 6], [1.25, 1, 0, 0], [1.415, 1, 0, 0], [1.585, 1, 0, 0], [12.75, 1, 0, 0], [0.04, 1, 0, 0], [2.125, 1, 1, 11], [0.875, 1, 0, 0], [0.375, 1, 1, 8], [0.75, 1, 1, 4], [1.75, 1, 1, 5], [1.085, 1, 1, 8], [0.04, 1, 1, 1], [0, 1, 1, 11], [1, 1, 1, 4], [3.25, 1, 1, 1], [1.75, 1, 1, 11], [1, 1, 1, 3], [1.5, 1, 1, 10], [1.29, 1, 1, 5], [1.335, 1, 1, 8], [0.04, 0, 1, 1], [0.125, 1, 0, 0], [5.25, 1, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0], [17.5, 1, 1, 9], [8.5, 1, 1, 9], [1, 1, 1, 5], [0.29, 1, 1, 7], [3.125, 1, 1, 8], [4.25, 1, 1, 3], [0.085, 0, 0, 0], [0.085, 1, 0, 0], [0.25, 1, 0, 0], [2.375, 1, 1, 8], [2.5, 1, 1, 3], [2, 1, 1, 11], [0.54, 1, 1, 4], [0.25, 0, 0, 0], [0.125, 0, 0, 0], [0.085, 1, 0, 0], [1.25, 0, 0, 0], [0.04, 0, 0, 0], [0.5, 0, 0, 0], [0.085, 0, 0, 0], [0.125, 0, 0, 0], [5.085, 0, 1, 2], [0.29, 0, 1, 1], [0.585, 0, 1, 2], [0.125, 0, 0, 0], [0.25, 0, 1, 2], [1.585, 0, 1, 1], [0, 0, 1, 2], [2, 0, 1, 1], [0.125, 1, 0, 0], [0.125, 0, 0, 0], [2.25, 0, 0, 0], [0.665, 0, 0, 0], [0.665, 0, 0, 0], [2.085, 0, 0, 0], [0, 0, 0, 0], [0.5, 0, 0, 0], [1.665, 0, 0, 0], [0.25, 0, 0, 0], [0.125, 0, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0], [0.25, 0, 1, 1], [0.96, 0, 1, 2], [0.5, 0, 0, 0], [0.79, 0, 0, 0], [0.25, 0, 0, 0], [1.5, 0, 0, 0], [2.5, 0, 0, 0], [3.5, 0, 0, 0], [3, 0, 0, 0], [0.29, 0, 0, 0], [0.165, 0, 0, 0], [0.165, 0, 0, 0], [0.25, 0, 0, 0], [3.5, 0, 0, 0], [0, 0, 1, 6], [1, 0, 0, 0], [0.125, 0, 1, 1], [0.335, 0, 0, 0], [0.5, 1, 0, 0], [0.415, 0, 1, 1], [0, 0, 0, 0], [2.29, 0, 1, 1], [0.25, 0, 0, 0], [1, 0, 0, 0], [0.25, 0, 1, 1], [0.085, 0, 0, 0], [0.165, 0, 0, 0], [0.875, 0, 0, 0], [1.5, 0, 0, 0], [0.04, 0, 0, 0], [0.04, 0, 0, 0], [0.25, 0, 0, 0], [1.75, 0, 1, 1], [0.085, 0, 0, 0], [1.5, 0, 0, 0], [5.5, 0, 0, 0], [0.5, 0, 0, 0], [0.5, 0, 0, 0], [0.21, 0, 0, 0], [0.665, 0, 0, 0], [0.085, 0, 1, 12], [0.04, 0, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0], [0.29, 0, 0, 0], [3, 0, 0, 0], [0.335, 0, 0, 0], [0.585, 0, 0, 0], [3.5, 0, 0, 0], [1.25, 0, 0, 0], [2, 0, 1, 2], [2, 0, 1, 1], [0.04, 0, 0, 0], [8.29, 0, 0, 0], [12.5, 1, 0, 0], [3, 1, 0, 0], [0.875, 1, 0, 0], [8.5, 1, 0, 0], [0.835, 1, 0, 0], [2.25, 1, 1, 6], [0, 0, 0, 0], [2.71, 1, 1, 5], [4.75, 1, 1, 2], [0.25, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 1, 2], [0.5, 0, 0, 0], [0.085, 0, 0, 0], [0, 0, 0, 0], [0.25, 0, 0, 0], [0.04, 0, 0, 0], [0.165, 0, 1, 2], [0, 0, 0, 0], [7, 0, 0, 0], [0.25, 0, 0, 0], [0, 0, 0, 0], [0.085, 0, 0, 0], [0.125, 0, 0, 0], [5, 1, 1, 3], [6.5, 1, 0, 0], [1.5, 1, 1, 1], [0.54, 1, 0, 0], [0, 0, 0, 0], [1, 0, 1, 1], [0, 0, 0, 0], [4.25, 0, 0, 0], [0, 0, 0, 0], [0.165, 0, 0, 0], [3.5, 0, 0, 0]] [[1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [' -'], [' -'], [' -'], [' -'], [' -'], [1], [1], [1], [1], [' -'], [1], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [' -'], [1], [1], [1], [' -'], [1], [1], [' -'], [' -'], [1], [' -'], [' -']]\n",
      "4 689\n"
     ]
    }
   ],
   "source": [
    "#Opening the Excel file with data\n",
    "filepath=\"credit_card_data.xlsx\" #Enter full filepath here\n",
    "wb=load_workbook(filepath)\n",
    "sheet=wb.active\n",
    "\n",
    "#set-wise data read-in \n",
    "def read(num):\n",
    "    x, y = [], []\n",
    "    \n",
    "# 1. Male, 2. Age, 3. Debt, 4. Married, 5. Bank Customer, 6. Education Level, 7. Ethnicity, 8. Years Employed, \n",
    "# 9.Prior Default, 10. Employed, 11. Credit Score, 12. Driver's License, 13. Citizen, 14. Zip Code, 15. Income\n",
    "\n",
    "#Considering data for only 4 columns\n",
    "    cols = [8, 9, 10, 11]\n",
    "    for i in cols:\n",
    "        x.append(sheet.cell(row=num+1,column=i).value)\n",
    "    y.append(sheet.cell(row=num+1,column=16).value)\n",
    "    return x, y\n",
    "\n",
    "x_data, y_data = [], []\n",
    "for j in range(1, 690):\n",
    "    valx, valy = read(j)\n",
    "    \n",
    "#Checks for missing data    \n",
    "    \n",
    "    if \"?\" in valx:\n",
    "        print(j, read(j))\n",
    "    x_data.append(valx)    \n",
    "    y_data.append(valy)\n",
    "print(x_data, y_data)\n",
    "print(len(x_data[0]), len(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Shuffle the order of the data\n",
    "toshuffle = list(zip(x_data, y_data))\n",
    "x_data, y_data = zip(*toshuffle)\n",
    "\n",
    "#Splitting into train and test set\n",
    "cut = 600\n",
    "train_x, train_y = x_data[0:cut], y_data[0:cut]\n",
    "test_x, test_y = x_data[cut:690], y_data[cut:690]\n",
    "\n",
    "train_x, train_y = np.asarray(train_x), np.asarray(train_y)\n",
    "test_x, test_y = np.asarray(test_x), np.asarray(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network (Shitij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Mean: 0.0\n",
      "New Mean: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Runs 10 iterations of ANN and gives out the mean accuracy of the highest 5 accuracies\n",
    "per_acc = []\n",
    "for i in range(10):\n",
    "   \n",
    "#Calling MLP classifier\n",
    "    ann = MLPClassifier(activation= 'tanh', hidden_layer_sizes= (100,), learning_rate= 'constant',  max_iter= 100, \n",
    "                      solver= 'lbfgs', tol= 0.01, validation_fraction= 0.1, early_stopping=True,\n",
    "                      n_iter_no_change=100, verbose=True)\n",
    "    \n",
    "#Training the network\n",
    "    train_y = np.asarray(train_y)\n",
    "    ann.fit(train_x, train_y.ravel())\n",
    "\n",
    "#Gives probabilistic predictions\n",
    "    prediction = ann.predict_proba(test_x)\n",
    "\n",
    "    c = 0\n",
    "    for each in range(len(prediction)):\n",
    "        if np.argmax(prediction[each]) == test_y[each]:\n",
    "            c += 1\n",
    "\n",
    "    per =  float(c / len(prediction)) * 100\n",
    "    print(per)\n",
    "    per_acc.append(per)\n",
    "\n",
    "print('Mean:', mean(per_acc))\n",
    "sort = nlargest(5, per_acc)\n",
    "print('New Mean:', mean(sort))\n",
    "x = np.arange(0, 10)\n",
    "plt.plot(x, per_acc)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Percentage Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Yusri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "New Mean: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Runs 10 iterations of LR and gives out the mean accuracy of the highest 5 accuracies\n",
    "per_acc=[]                                                                   \n",
    "for i in range(10):\n",
    "\n",
    "    lr = LogisticRegression(C=0.9, penalty='l1', tol=0.01)\n",
    "    lr.fit(train_x, train_y)\n",
    "    y_pred=lr.predict(test_x)\n",
    "\n",
    "    score = metrics.accuracy_score(test_y, y_pred)\n",
    "    print(score)\n",
    "    per_acc.append(score)\n",
    "    \n",
    "print(mean(per_acc))\n",
    "sort = nlargest(5, per_acc)\n",
    "print('New Mean:', mean(sort))\n",
    "x = list(range(len(per_acc)))\n",
    "plt.plot(x,per_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (YuanJea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Accuracy:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Just one iteration as it returns consistent results for every iteration \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15, weights='uniform', algorithm='auto', leaf_size=1, p=1 ,metric='minkowski')\n",
    "\n",
    "knn.fit(train_x, train_y)\n",
    "\n",
    "predicted = knn.predict_proba(test_x)\n",
    "\n",
    "c = 0\n",
    "for each in range(len(predicted)):\n",
    "    if np.argmax(predicted[each]) == test_y[each]:    \n",
    "        c += 1\n",
    "\n",
    "print(\"Percentage Accuracy: \", float(c/len(predicted))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (Yusri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Accuracy: 0.0\n",
      "Mean:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mylist=[]\n",
    "for i in range(10):\n",
    "    \n",
    "    svm = SVC(kernel= 'linear', C= 1.) #svm Classifier\n",
    "    svm.fit(train_x, train_y)          #Train the model using the training sets\n",
    "    y_pred = svm.predict(test_x)               #Predict the response for test datasetfrom sklearn import metric\n",
    "\n",
    "    x = metrics.accuracy_score(test_y, y_pred)*100\n",
    "\n",
    "    print(\"Accuracy:\" , x )\n",
    "    mylist.append(x)\n",
    "\n",
    "print(\"Mean: \" , mean(mylist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (Deryck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7415730337078652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7415730337078652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7303370786516854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7528089887640449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7415730337078652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7415730337078652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7303370786516854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7528089887640449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7303370786516854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier has accuracy of:  0.7415730337078652\n",
      "0.7404494382022472\n",
      "New Mean: 0.7460674157303371\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Runs 10 iterations of RF and gives out the mean accuracy of the highest 5 accuracies\n",
    "\n",
    "per_acc=[]                                                                   \n",
    "for i in range(10):\n",
    "    rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',max_depth=None, max_features='auto',\n",
    "                                max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=2,\n",
    "                                min_samples_split=4, min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                                oob_score=False, verbose=0, warm_start=False)\n",
    "    rf.fit(train_x, train_y)\n",
    "    y_pred = rf.predict(test_x)\n",
    "    print(\"Random Forest classifier has accuracy of: \", rf.score(test_x, test_y))\n",
    "    per_acc.append(rf.score(test_x, test_y))\n",
    "    \n",
    "print(mean(per_acc))\n",
    "sort = nlargest(5, per_acc)\n",
    "print('New Mean:', mean(sort))\n",
    "\n",
    "x = list(range(len(per_acc)))\n",
    "plt.plot(x,per_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees (Deryck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7415730337078652\n",
      "Accuracy: 0.7303370786516854\n",
      "Accuracy: 0.7191011235955056\n",
      "Accuracy: 0.7191011235955056\n",
      "Accuracy: 0.7191011235955056\n",
      "Accuracy: 0.7191011235955056\n",
      "Accuracy: 0.7415730337078652\n",
      "Accuracy: 0.7303370786516854\n",
      "Accuracy: 0.7415730337078652\n",
      "Accuracy: 0.7191011235955056\n",
      "0.7280898876404495\n",
      "New Mean: 0.7370786516853933\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_acc=[]\n",
    "for i in range(10):\n",
    "    tree = DecisionTreeClassifier(max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                  min_samples_leaf=3, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False,\n",
    "                                  random_state=None, splitter='best')\n",
    "    tree = tree.fit(train_x, train_y)\n",
    "    print(\"Accuracy:\", tree.score(test_x, test_y))\n",
    "    per_acc.append(tree.score(test_x, test_y))\n",
    "    \n",
    "\n",
    "print(mean(per_acc))\n",
    "sort = nlargest(5, per_acc)\n",
    "print('New Mean:', mean(sort))\n",
    "\n",
    "x = list(range(len(per_acc)))\n",
    "plt.plot(x,per_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False))]\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform'))]\n",
      "[('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n",
      "[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n",
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)), ('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform')), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'))]\n"
     ]
    }
   ],
   "source": [
    "#Ensembling by using a voting classifier\n",
    "\n",
    "alg = [('ann', ann), ('lr', lr), ('knn', knn), ('svm', svm), ('rf', rf), ('dt', tree)]\n",
    "\n",
    "#Creates all possible combinations of the individual algorithms used\n",
    "combs, allcombs = [], []\n",
    "for i in range(1, len(alg)+1):\n",
    "    els = [list(x) for x in combinations(alg, i)]\n",
    "    combs.append(els)\n",
    "\n",
    "for i in combs:\n",
    "    for j in i:\n",
    "        allcombs.append(j)\n",
    "        print(j)\n",
    "\n",
    "# allcombs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling for all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ann', MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "              n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False))]\n",
      "Mean: 0.8049438202247191\n",
      "Stdev: 0.005902014867046632\n",
      "New Mean: 0.8089887640449438\n",
      "New Stdev: 0.0\n",
      "Avg Time: 0.061329345703125\n",
      "1 iterations done out of 64\n",
      "[('lr', LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.01, verbose=0,\n",
      "                   warm_start=False))]\n",
      "Mean: 0.8202247191011236\n",
      "Stdev: 0.0\n",
      "New Mean: 0.8202247191011236\n",
      "New Stdev: 0.0\n",
      "Avg Time: 0.003789238929748535\n",
      "2 iterations done out of 64\n",
      "[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform'))]\n",
      "Mean: 0.7752808988764045\n",
      "Stdev: 0.0\n",
      "New Mean: 0.7752808988764045\n",
      "New Stdev: 0.0\n",
      "Avg Time: 0.005864295959472656\n",
      "3 iterations done out of 64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1f7cb5b53594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0meclf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0meclf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meclf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meclf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\voting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'soft'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mmaj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'hard' voting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\voting.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    318\u001b[0m                                  \" voting=%r\" % self.voting)\n\u001b[0;32m    319\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[0m\u001b[0;32m    321\u001b[0m                          weights=self._weights_not_none)\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \"\"\"\n\u001b[1;32m--> 616\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    584\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    585\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "#Returns mean, standard deviation and run time for accuracies from 50 iterations of each combination.\n",
    "#Also returns the mean and standard deviation for the top 5 iterations in terms of the accuracies\n",
    "\n",
    "mod4, accs4, times4, allofem4 = [], [], [], []\n",
    "counter = 0\n",
    "for i in allcombs:\n",
    "    acc = []\n",
    "    start = time()\n",
    "    for j in range(0, 50):\n",
    "#Voting classifier from scikit-learn\n",
    "        eclf1 = VotingClassifier(estimators=[i[0]], voting='soft')\n",
    "        eclf1 = eclf1.fit(train_x, train_y.ravel())\n",
    "        pred = eclf1.predict(test_x)\n",
    "        acc.append(metrics.accuracy_score(test_y, pred))\n",
    "    end = time()\n",
    "    tt = end - start\n",
    "#Selects 5 largest accuracies\n",
    "    sort = nlargest(5, acc)\n",
    "    print(i)\n",
    "    print('Mean:', mean(acc))\n",
    "    print('Stdev:', stdev(acc))\n",
    "    print('New Mean:', mean(sort))\n",
    "    print('New Stdev:', stdev(sort))\n",
    "    print('Avg Time:', tt/50)\n",
    "    mod4.append(i)\n",
    "    accs4.append((mean(acc), stdev(acc), mean(sort), stdev(sort)))\n",
    "    times4.append(tt/50)\n",
    "    allofem4.append((i, mean(acc), stdev(acc), mean(sort), stdev(sort), tt/50))\n",
    "    counter += 1\n",
    "    print('%d iterations done out of 63' %counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False))],\n",
       "  0.927,\n",
       "  0.004830458915396484,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.03837428092956543),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.002493119239807129),\n",
       " ([('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform'))],\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.007180929183959961),\n",
       " ([('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0040891170501708984),\n",
       " ([('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.91,\n",
       "  0.0,\n",
       "  0.91,\n",
       "  0.0,\n",
       "  0.19657430648803711),\n",
       " ([('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.906,\n",
       "  0.006992058987801017,\n",
       "  0.91,\n",
       "  0.0,\n",
       "  0.0019945383071899416),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False))],\n",
       "  0.929,\n",
       "  0.003162277660168382,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0411257266998291),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform'))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0405914306640625),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False))],\n",
       "  0.927,\n",
       "  0.004830458915396484,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.03929474353790283),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.926,\n",
       "  0.005163977794943227,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.04089059829711914),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.036801600456237794),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0020943403244018553),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.001994609832763672),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0020974397659301756),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0021941661834716797),\n",
       " ([('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False))],\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.006080794334411621),\n",
       " ([('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.009275174140930176),\n",
       " ([('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.006781840324401855),\n",
       " ([('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.003789854049682617),\n",
       " ([('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.003989696502685547),\n",
       " ([('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.91,\n",
       "  0.0,\n",
       "  0.91,\n",
       "  0.0,\n",
       "  0.2694791555404663),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform'))],\n",
       "  0.927,\n",
       "  0.004830458915396484,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.04061493873596191),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False))],\n",
       "  0.929,\n",
       "  0.003162277660168382,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.03879601955413818),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.040691184997558597),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.929,\n",
       "  0.003162277660168382,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.03739998340606689),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False))],\n",
       "  0.926,\n",
       "  0.005163977794943227,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.04880292415618896),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.927,\n",
       "  0.009486832980505146,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.04069123268127441),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.927,\n",
       "  0.004830458915396484,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.04737343788146973),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.929,\n",
       "  0.003162277660168382,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.03540525436401367),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.929,\n",
       "  0.003162277660168382,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.045247340202331544),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.924,\n",
       "  0.005163977794943227,\n",
       "  0.928,\n",
       "  0.004472135954999584,\n",
       "  0.02862370014190674),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.003989195823669434),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0036904335021972655),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0039892435073852536),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.003091740608215332),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.002992081642150879),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0029920101165771484),\n",
       " ([('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.010571527481079101),\n",
       " ([('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.009474682807922363),\n",
       " ([('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.005585098266601562),\n",
       " ([('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.004288578033447265),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.03250942230224609),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.030618166923522948),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.929,\n",
       "  0.003162277660168382,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.025892424583435058),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.925,\n",
       "  0.0052704627669473035,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.02712743282318115),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.927,\n",
       "  0.004830458915396484,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.035804224014282224),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.02702779769897461),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.036402654647827146),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.927,\n",
       "  0.004830458915396484,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.038796401023864745),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.028523635864257813),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.030518388748168944),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0026927947998046874),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.002892279624938965),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.002593231201171875),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.0025931835174560548),\n",
       " ([('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.88,\n",
       "  0.0,\n",
       "  0.005584979057312011),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False))],\n",
       "  0.922,\n",
       "  0.010327955589886454,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.026514577865600585),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.928,\n",
       "  0.004216370213557843,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.028121590614318848),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.927,\n",
       "  0.004830458915396484,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.029520034790039062),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.925,\n",
       "  0.0052704627669473035,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.025930571556091308),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.926,\n",
       "  0.006992058987801017,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.029606103897094727),\n",
       " ([('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.002892160415649414),\n",
       " ([('ann',\n",
       "    MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                  beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "                  hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                  learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "                  n_iter_no_change=100, nesterovs_momentum=True, power_t=0.5,\n",
       "                  random_state=None, shuffle=True, solver='lbfgs', tol=0.01,\n",
       "                  validation_fraction=0.1, verbose=True, warm_start=False)),\n",
       "   ('lr',\n",
       "    LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                       multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                       random_state=None, solver='warn', tol=0.01, verbose=0,\n",
       "                       warm_start=False)),\n",
       "   ('knn',\n",
       "    KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
       "                         metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
       "                         weights='uniform')),\n",
       "   ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "        kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "        shrinking=True, tol=0.001, verbose=False)),\n",
       "   ('rf',\n",
       "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=2, min_samples_split=4,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_jobs=None, oob_score=False, random_state=None,\n",
       "                           verbose=0, warm_start=False)),\n",
       "   ('dt',\n",
       "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                           max_features='sqrt', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=3, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, presort=False,\n",
       "                           random_state=None, splitter='best'))],\n",
       "  0.925,\n",
       "  0.0052704627669473035,\n",
       "  0.93,\n",
       "  0.0,\n",
       "  0.033311104774475096)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prints cumulative results from the above cell\n",
    "allofem4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
